{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning signal\n",
      "cleaning signal\n",
      "cleaning signal\n",
      "cleaning signal\n",
      "cleaning signal\n",
      "cleaning signal\n",
      "cleaning signal\n",
      "cleaning signal\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import PostProcessing_Functions5 as Fun\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "safeProcessors = max(1, mp.cpu_count() - 2)\n",
    "pool2 = mp.Pool(safeProcessors)\n",
    "\n",
    "directory = \"/home/david/BioResearch/python/PostProcessing/Simulations/beta0.05/\"\n",
    "directory2 = \"/home/david/BioResearch/python/\"\n",
    "file_names = np.array(pd.read_csv(directory+'1metadata.csv', header=None))\n",
    "heat_map_axes = [16]\n",
    "heat_map_axes0 = [1]\n",
    "heat_map_matrices = np.zeros([4, file_names.shape[0], file_names.shape[1]])\n",
    "\n",
    "# representative_series = np.genfromtxt(file_names[7, 5], delimiter=',')\n",
    "# plt.plot(representative_series[:, 0], representative_series[:, 1])\n",
    "# plt.ylabel('protein count')\n",
    "# plt.xlabel('time (min)')\n",
    "# plt.title('Raw Data from Gillespie')\n",
    "# plt.show()\n",
    "#\n",
    "# after_burn_in = Fun.burn_in_time_series(representative_series, 100)\n",
    "# plt.plot(after_burn_in[:, 0], after_burn_in[:, 1])\n",
    "# plt.ylabel('protein count')\n",
    "# plt.xlabel('time (min)')\n",
    "# plt.title('Raw Data after Burn in for 100 min')\n",
    "# plt.show()\n",
    "#\n",
    "# after_uniform_sampling = Fun.uniformly_sample(after_burn_in, 2000)\n",
    "# plt.plot(after_uniform_sampling[:, 0], after_uniform_sampling[:, 1])\n",
    "# plt.ylabel('protein count')\n",
    "# plt.xlabel('time (min)')\n",
    "# plt.title('Uniformly sampled time series')\n",
    "# plt.show()\n",
    "#\n",
    "# after_low_pass = Fun.low_pass_filter(after_uniform_sampling, [1/256, 1/32, 7/64, 7/32, 35/128, 7/32, 7/64, 1/32, 1/256])\n",
    "# plt.plot(after_low_pass[:, 0], after_low_pass[:, 1])\n",
    "# plt.ylabel('protein count')\n",
    "# plt.xlabel('time (min)')\n",
    "# plt.title('Low-passed time series')\n",
    "# plt.show()\n",
    "#\n",
    "# after_peak_detection = Fun.detect_peaks(after_low_pass)\n",
    "# plt.plot(after_low_pass[:, 0], after_low_pass[:, 1])\n",
    "# plt.scatter(after_peak_detection[:, 0], after_peak_detection[:, 1])\n",
    "# plt.ylabel('protein count')\n",
    "# plt.xlabel('time (min)')\n",
    "# plt.title('Time Series with peaks detected')\n",
    "# plt.show()\n",
    "\n",
    "def cleanStatsHeatMap(directory2,file_names, mean_axis,cv_axis):\n",
    "    with open(directory2 + file_names[mean_axis, cv_axis]) as file:\n",
    "        length = len(list(csv.reader(file)))\n",
    "    t1 = time.time()\n",
    "    stats = Fun.all_together_now(np.genfromtxt(file_names[mean_axis, cv_axis], delimiter=','),\n",
    "                                 int(length*.02), 100, [1/256, 1/32, 7/64, 7/32, 35/128, 7/32, 7/64, 1/32, 1/256])\n",
    "    heat_map_matrices[:, mean_axis, cv_axis] = stats\n",
    "\n",
    "    pass\n",
    "\n",
    "for mean_axis in range(file_names.shape[0]):\n",
    "    pool2.starmap(cleanStatsHeatMap, [(directory2,file_names, mean_axis,cv_axis) for cv_axis in range(file_names.shape[1])])\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "pool2.close()\n",
    "pool2.join()\n",
    "mean_period = pd.DataFrame(heat_map_matrices[0, :, :])\n",
    "mean_amplitude = pd.DataFrame(heat_map_matrices[1, :, :])\n",
    "period_CV = pd.DataFrame(heat_map_matrices[2, :, :])\n",
    "amplitude_CV = pd.DataFrame(heat_map_matrices[3, :, :])\n",
    "\n",
    "mean_period.to_csv(directory + 'mean_period.csv')\n",
    "mean_amplitude.to_csv(directory + 'mean_amplitude.csv')\n",
    "period_CV.to_csv(directory + 'period_CV.csv')\n",
    "amplitude_CV.to_csv(directory + 'amplitude_CV.csv')\n",
    "\n",
    "mean_period_heat_map = Fun.generate_heat_map(mean_period, 'Mean Period', ['CV of Delay', 'Delay Mean (min)'],\n",
    "                                             np.mean(list(heat_map_matrices[0, :, :])))\n",
    "mean_amplitude_heat_map = Fun.generate_heat_map(mean_amplitude, 'Mean Amplitude', ['CV of Delay', 'Delay Mean (min)'],\n",
    "                                                np.mean(list(heat_map_matrices[1, :, :])))\n",
    "period_CV_heat_map = Fun.generate_heat_map(period_CV, 'CV of Period', ['CV of Delay', 'Delay Mean (min)'],\n",
    "                                           np.mean(list(heat_map_matrices[2, :, :])))\n",
    "amplitude_CV_heat_map = Fun.generate_heat_map(amplitude_CV, 'CV of Amplitude', ['CV of Delay', 'Delay Mean (min)'],\n",
    "                                              np.mean(list(heat_map_matrices[3, :, :])))\n",
    "\n",
    "normalized_heat_map_matricies = np.zeros(heat_map_matrices.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
